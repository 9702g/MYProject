{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7507630,"sourceType":"datasetVersion","datasetId":4372405}],"dockerImageVersionId":30635,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#importing the required libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"execution":{"iopub.status.busy":"2024-01-29T17:24:50.092840Z","iopub.execute_input":"2024-01-29T17:24:50.093223Z","iopub.status.idle":"2024-01-29T17:24:51.886805Z","shell.execute_reply.started":"2024-01-29T17:24:50.093191Z","shell.execute_reply":"2024-01-29T17:24:51.885673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#reading the required dataset\ndata=pd.read_csv('/kaggle/input/clean-kenyan-dataset/Clean_Kenya_Tourism_datasets (2).csv')","metadata":{"execution":{"iopub.status.busy":"2024-01-29T17:26:57.837384Z","iopub.execute_input":"2024-01-29T17:26:57.837802Z","iopub.status.idle":"2024-01-29T17:26:57.870536Z","shell.execute_reply.started":"2024-01-29T17:26:57.837769Z","shell.execute_reply":"2024-01-29T17:26:57.869384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#checking the first five rows of the training data\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2024-01-29T17:27:05.821493Z","iopub.execute_input":"2024-01-29T17:27:05.822660Z","iopub.status.idle":"2024-01-29T17:27:05.860330Z","shell.execute_reply.started":"2024-01-29T17:27:05.822620Z","shell.execute_reply":"2024-01-29T17:27:05.859218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#checking the columns in the training dataset\ndata.columns","metadata":{"execution":{"iopub.status.busy":"2024-01-29T17:27:15.795424Z","iopub.execute_input":"2024-01-29T17:27:15.795828Z","iopub.status.idle":"2024-01-29T17:27:15.803515Z","shell.execute_reply.started":"2024-01-29T17:27:15.795794Z","shell.execute_reply":"2024-01-29T17:27:15.802210Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#checking the information of the training dataset\ndata.info()","metadata":{"execution":{"iopub.status.busy":"2024-01-29T17:29:11.429732Z","iopub.execute_input":"2024-01-29T17:29:11.430138Z","iopub.status.idle":"2024-01-29T17:29:11.459912Z","shell.execute_reply.started":"2024-01-29T17:29:11.430105Z","shell.execute_reply":"2024-01-29T17:29:11.458860Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#step 2 is to clean the data\n#replacing the nan values in the travel_with column of the training data with Alone\n\ndata['travel_with'] = data['travel_with'].replace(np.nan, 'Alone')","metadata":{"execution":{"iopub.status.busy":"2024-01-29T17:33:27.797724Z","iopub.execute_input":"2024-01-29T17:33:27.798369Z","iopub.status.idle":"2024-01-29T17:33:27.804553Z","shell.execute_reply.started":"2024-01-29T17:33:27.798327Z","shell.execute_reply":"2024-01-29T17:33:27.803875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#replacing the nan values in the total_female column of the training data with 1.0\n\ndata['total_female'] = data['total_female'].replace(np.nan, 1.0)","metadata":{"execution":{"iopub.status.busy":"2024-01-29T17:36:44.486433Z","iopub.execute_input":"2024-01-29T17:36:44.486861Z","iopub.status.idle":"2024-01-29T17:36:44.492856Z","shell.execute_reply.started":"2024-01-29T17:36:44.486831Z","shell.execute_reply":"2024-01-29T17:36:44.491853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#replacing the nan values in the total_male column of the training data with 1.0\n\ndata['total_male'] = data['total_male'].replace(np.nan, 1.0)","metadata":{"execution":{"iopub.status.busy":"2024-01-29T17:36:48.234547Z","iopub.execute_input":"2024-01-29T17:36:48.235459Z","iopub.status.idle":"2024-01-29T17:36:48.240144Z","shell.execute_reply.started":"2024-01-29T17:36:48.235424Z","shell.execute_reply":"2024-01-29T17:36:48.239415Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#replacing the nan values in the most_impressing column of the training data with No comments\n\ndata['most_impressing'] = data['most_impressing'].replace(np.nan, 'No comments')","metadata":{"execution":{"iopub.status.busy":"2024-01-29T17:36:50.895916Z","iopub.execute_input":"2024-01-29T17:36:50.897138Z","iopub.status.idle":"2024-01-29T17:36:50.902999Z","shell.execute_reply.started":"2024-01-29T17:36:50.897099Z","shell.execute_reply":"2024-01-29T17:36:50.901877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#replacing 24-jan to 1-24 to correlate with \n\ndata['age_group'] = data['age_group'].replace('24-Jan', '1-24')","metadata":{"execution":{"iopub.status.busy":"2024-01-29T17:36:54.579056Z","iopub.execute_input":"2024-01-29T17:36:54.579408Z","iopub.status.idle":"2024-01-29T17:36:54.585056Z","shell.execute_reply.started":"2024-01-29T17:36:54.579380Z","shell.execute_reply":"2024-01-29T17:36:54.583912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\nfrom xgboost import XGBRegressor","metadata":{"execution":{"iopub.status.busy":"2024-01-29T17:37:33.778545Z","iopub.execute_input":"2024-01-29T17:37:33.778935Z","iopub.status.idle":"2024-01-29T17:37:33.784120Z","shell.execute_reply.started":"2024-01-29T17:37:33.778904Z","shell.execute_reply":"2024-01-29T17:37:33.783392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"execution":{"iopub.status.busy":"2024-01-29T17:38:52.267703Z","iopub.execute_input":"2024-01-29T17:38:52.268107Z","iopub.status.idle":"2024-01-29T17:38:52.293856Z","shell.execute_reply.started":"2024-01-29T17:38:52.268072Z","shell.execute_reply":"2024-01-29T17:38:52.292689Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# %convert float dtypes to int[total_female,total_male,night_mainland,night_zanzibar]\ndata[\"total_female\"] = data['total_female'].astype('int')\ndata[\"total_male\"] = data['total_male'].astype('int')\ndata[\"night_mainland\"] = data['night_mainland'].astype('int')\n","metadata":{"execution":{"iopub.status.busy":"2024-01-29T17:51:26.784770Z","iopub.execute_input":"2024-01-29T17:51:26.785213Z","iopub.status.idle":"2024-01-29T17:51:26.792852Z","shell.execute_reply.started":"2024-01-29T17:51:26.785181Z","shell.execute_reply":"2024-01-29T17:51:26.791966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# %Let's generate new features from some columns which makes some sense\ndata[\"total_people\"] = data[\"total_female\"] + data[\"total_male\"]\n\ndata[\"total_nights\"] = data[\"night_mainland\"] ","metadata":{"execution":{"iopub.status.busy":"2024-01-29T17:52:32.000685Z","iopub.execute_input":"2024-01-29T17:52:32.001140Z","iopub.status.idle":"2024-01-29T17:52:32.008559Z","shell.execute_reply.started":"2024-01-29T17:52:32.001106Z","shell.execute_reply":"2024-01-29T17:52:32.007338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# %more information about data\ndata.info()","metadata":{"execution":{"iopub.status.busy":"2024-01-29T17:52:58.933122Z","iopub.execute_input":"2024-01-29T17:52:58.933622Z","iopub.status.idle":"2024-01-29T17:52:58.954547Z","shell.execute_reply.started":"2024-01-29T17:52:58.933588Z","shell.execute_reply":"2024-01-29T17:52:58.953578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# %Before hand let's remove ID Column\ndata.drop('ID', axis='columns', inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-01-29T17:54:27.038039Z","iopub.execute_input":"2024-01-29T17:54:27.039067Z","iopub.status.idle":"2024-01-29T17:54:27.047821Z","shell.execute_reply.started":"2024-01-29T17:54:27.039004Z","shell.execute_reply":"2024-01-29T17:54:27.046696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"execution":{"iopub.status.busy":"2024-01-29T17:54:39.443576Z","iopub.execute_input":"2024-01-29T17:54:39.443964Z","iopub.status.idle":"2024-01-29T17:54:39.468112Z","shell.execute_reply.started":"2024-01-29T17:54:39.443934Z","shell.execute_reply":"2024-01-29T17:54:39.467083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# %then it's time to encode objects into numeric\n\nfor colname in data.select_dtypes(\"object\"):\n    data[colname],_=data[colname].factorize()","metadata":{"execution":{"iopub.status.busy":"2024-01-29T17:56:11.848034Z","iopub.execute_input":"2024-01-29T17:56:11.848443Z","iopub.status.idle":"2024-01-29T17:56:11.869372Z","shell.execute_reply.started":"2024-01-29T17:56:11.848411Z","shell.execute_reply":"2024-01-29T17:56:11.868298Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"execution":{"iopub.status.busy":"2024-01-29T17:56:22.391628Z","iopub.execute_input":"2024-01-29T17:56:22.392100Z","iopub.status.idle":"2024-01-29T17:56:22.411368Z","shell.execute_reply.started":"2024-01-29T17:56:22.392062Z","shell.execute_reply":"2024-01-29T17:56:22.410319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# Step 3 model building\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2024-01-29T17:56:54.137394Z","iopub.execute_input":"2024-01-29T17:56:54.137934Z","iopub.status.idle":"2024-01-29T17:56:54.143521Z","shell.execute_reply.started":"2024-01-29T17:56:54.137899Z","shell.execute_reply":"2024-01-29T17:56:54.142373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# %spliting dependent and independent features\n# Drop the \"total_cost\" column\nfeatures_cols = data.drop(columns=[\"total_cost\"])\n\n# Now 'features_cols' contains the DataFrame without the \"total_cost\" column\n\ncols = features_cols.columns\ntarget=data[\"total_cost\"]","metadata":{"execution":{"iopub.status.busy":"2024-01-29T18:04:09.517838Z","iopub.execute_input":"2024-01-29T18:04:09.518219Z","iopub.status.idle":"2024-01-29T18:04:09.525084Z","shell.execute_reply.started":"2024-01-29T18:04:09.518190Z","shell.execute_reply":"2024-01-29T18:04:09.524313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data[cols].shape , target.shape","metadata":{"execution":{"iopub.status.busy":"2024-01-29T18:04:30.897046Z","iopub.execute_input":"2024-01-29T18:04:30.897403Z","iopub.status.idle":"2024-01-29T18:04:30.905448Z","shell.execute_reply.started":"2024-01-29T18:04:30.897377Z","shell.execute_reply":"2024-01-29T18:04:30.904526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"((4809, 22), (4809,))","metadata":{}},{"cell_type":"code","source":"#modelling\n# %Let's set seed for reproducibility of our final model\nSEED = 2020 #you can set any number\nfrom sklearn.model_selection import train_test_split\n# create training and testing vars\nX_train, X_test, y_train, y_test = train_test_split(data[cols],target, test_size=0.20, random_state = SEED)\nprint (X_train.shape, y_train.shape)\nprint (X_test.shape, y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2024-01-29T18:05:30.277584Z","iopub.execute_input":"2024-01-29T18:05:30.277996Z","iopub.status.idle":"2024-01-29T18:05:30.294896Z","shell.execute_reply.started":"2024-01-29T18:05:30.277965Z","shell.execute_reply":"2024-01-29T18:05:30.294090Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"(3847, 23) (3847,)\n(962, 23) (962,)","metadata":{}},{"cell_type":"code","source":"#LINEAR REGRESSION\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error \n# %Model initialization & training\nLR = LinearRegression().fit(X_train,y_train)\n\n# %Predictions\ny_train_pred = LR.predict(X_train)\ny_test_pred = LR.predict(X_test)\n\n# % Evaluation\nmae = mean_absolute_error(y_test, y_test_pred)\nprint('Using scikit-lean, the mae error is {}'.format(mae))","metadata":{"execution":{"iopub.status.busy":"2024-01-29T18:06:15.761672Z","iopub.execute_input":"2024-01-29T18:06:15.762094Z","iopub.status.idle":"2024-01-29T18:06:15.842720Z","shell.execute_reply.started":"2024-01-29T18:06:15.762059Z","shell.execute_reply":"2024-01-29T18:06:15.840796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Using scikit-lean, the mae error is 5742313.756659567","metadata":{}},{"cell_type":"code","source":"# % Evaluation\nmse = mean_squared_error(y_test, y_test_pred)\nprint('Using scikit-lean, the mse error is {}'.format(mse))","metadata":{"execution":{"iopub.status.busy":"2024-01-29T18:06:39.064556Z","iopub.execute_input":"2024-01-29T18:06:39.064941Z","iopub.status.idle":"2024-01-29T18:06:39.071313Z","shell.execute_reply.started":"2024-01-29T18:06:39.064912Z","shell.execute_reply":"2024-01-29T18:06:39.070271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#EXTREME GRADIENT BOOST\nfrom xgboost import XGBRegressor\n","metadata":{"execution":{"iopub.status.busy":"2024-01-29T18:07:08.488589Z","iopub.execute_input":"2024-01-29T18:07:08.489350Z","iopub.status.idle":"2024-01-29T18:07:08.492917Z","shell.execute_reply.started":"2024-01-29T18:07:08.489314Z","shell.execute_reply":"2024-01-29T18:07:08.492205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# %instatiate the model\nXGB = XGBRegressor()\n\n# %training the model\nXGB.fit(X_train, y_train)\n\n# %prediction\ny_train_pred = XGB.predict(X_train)\ny_test_pred = XGB.predict(X_test)\n\n# % Evaluation\nmae = mean_absolute_error(y_test, y_test_pred)\nprint('Using scikit-lean, the mae error is {}'.format(mae))\n\nmse = mean_squared_error(y_test, y_test_pred)\nprint('Using scikit-lean, the mse error is {}'.format(mse))","metadata":{"execution":{"iopub.status.busy":"2024-01-29T18:07:22.307927Z","iopub.execute_input":"2024-01-29T18:07:22.308339Z","iopub.status.idle":"2024-01-29T18:07:22.518501Z","shell.execute_reply.started":"2024-01-29T18:07:22.308307Z","shell.execute_reply":"2024-01-29T18:07:22.517652Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here we can observe changes XGBRegression shows to perform well compared to Linear Regression even without passing some parameters.\n\nNot bad for such a lazy implementation, even without data normalization After all, the data will not always be so \"good\". So don't forget to pre-process the data. Now let's apply polynomial features technique on the data. And look at the result.","metadata":{}},{"cell_type":"markdown","source":"APPLYING POLYNOMIAL FEATURES\nPolynomial features are those features created by raising existing features to an exponent.\n\nFor example, if a dataset had one input feature X, then a polynomial feature would be the addition of a new feature (column) where values were calculated by squaring the values in X, e.g. X^2. This process can be repeated for each input variable in the dataset, creating a transformed version of each.\n\nAs such, polynomial features are a type of feature engineering, e.g. the creation of new input features based on the existing features.\n\nThe “degree” of the polynomial is used to control the number of features added, e.g. a degree of 3 will add two new variables for each input variable. Typically a small degree is used such as 2 or 3.\n\n*Generally speaking, it is unusual to use d greater than 3 or 4 because for large values of d, the polynomial curve can become overly flexible and can take on some very strange shapes.*","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import PolynomialFeatures\n# % applying polynomial features with 2 degree\nquad = PolynomialFeatures (degree = 2)\nx_quad = quad.fit_transform(data[cols])\n\nX_train,X_test,y_train,y_test = train_test_split(x_quad,target, random_state = 0)\n# %instatiate the model\nXGB_par_ = XGBRegressor(n_estimators= 100, colsample_bynode = 0.8, learning_rate = 0.02,max_depth =  7)\n\n# %training the model\nXGB_par_.fit(X_train, y_train)\n\n# %prediction\ny_train_pred = XGB_par_.predict(X_train)\ny_test_pred = XGB_par_.predict(X_test)\n\n# % Evaluation\nmae = mean_absolute_error(y_test, y_test_pred)\nprint('Using scikit-lean, the mae error is {}'.format(mae))\n\nmse = mean_squared_error(y_test, y_test_pred)\nprint('Using scikit-lean, the mse error is {}'.format(mse))","metadata":{"execution":{"iopub.status.busy":"2024-01-29T18:10:15.237518Z","iopub.execute_input":"2024-01-29T18:10:15.237932Z","iopub.status.idle":"2024-01-29T18:10:16.600802Z","shell.execute_reply.started":"2024-01-29T18:10:15.237900Z","shell.execute_reply":"2024-01-29T18:10:16.600025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Using scikit-lean, the mae error is 5370262.699263508\nUsing scikit-lean, the mse error is 98250845059727.06","metadata":{}},{"cell_type":"markdown","source":"EXTREME GRADIENT BOOST WITH PARAMETERS","metadata":{}},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(data[cols],target, test_size=0.20, random_state = SEED)\n\n# %instatiate the model\nXGB_par = XGBRegressor( n_estimators= 100, colsample_bynode = 0.8, learning_rate = 0.02,max_depth =  7)\n\n# %training the model\nXGB_par.fit(X_train, y_train)\n\n# %prediction\ny_train_pred = XGB_par.predict(X_train)\ny_test_pred = XGB_par.predict(X_test)\n\n# % Evaluation\nmae = mean_absolute_error(y_test, y_test_pred)\nprint('Using scikit-lean, the mae error is {}'.format(mae))\n\nmse = mean_squared_error(y_test, y_test_pred)\nprint('Using scikit-lean, the mse error is {}'.format(mse))","metadata":{"execution":{"iopub.status.busy":"2024-01-29T18:12:44.702482Z","iopub.execute_input":"2024-01-29T18:12:44.702846Z","iopub.status.idle":"2024-01-29T18:12:44.910270Z","shell.execute_reply.started":"2024-01-29T18:12:44.702819Z","shell.execute_reply":"2024-01-29T18:12:44.909502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Using scikit-lean, the mae error is 5109772.414642411\nUsing scikit-lean, the mse error is 93266365624137.86","metadata":{}},{"cell_type":"markdown","source":"Now we can see polynomial features technique does not improve the performance real well compared to Extreme gradient boost with parameter only. This shows that most of features were categorical applying polynomial feature engineering not the best approach ,may be you can try applying only to those numeric features and then concatinate with others","metadata":{}},{"cell_type":"markdown","source":"VISUALIZE PREDICTIONS","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.figure(figsize=(15,7))\n\nplt.scatter(y_train_pred,y_train_pred - y_train,\n          c = 'black', marker = 'o', s = 50, alpha = 0.5,\n          label = 'Train data')\nplt.scatter(y_test_pred,y_test_pred - y_test,\n          c = 'g', marker = 'o', s = 50, alpha = 0.7,\n          label = 'Test data')\nplt.xlabel('Predicted values')\nplt.ylabel('Tailings')\nplt.legend(loc = 'upper right')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-01-29T18:15:34.888299Z","iopub.execute_input":"2024-01-29T18:15:34.888784Z","iopub.status.idle":"2024-01-29T18:15:35.697180Z","shell.execute_reply.started":"2024-01-29T18:15:34.888739Z","shell.execute_reply":"2024-01-29T18:15:35.696068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"#Let's Visualize on the best contributed features\nfeat_importances = pd.Series(XGB_par.feature_importances_, index=cols)\nplt.figure(figsize=(15,10))\nplt.title(\"FEATURE IMPORTANCE PLOT\")\nfeat_importances.nlargest(18).plot(kind='barh')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-01-29T18:16:35.736657Z","iopub.execute_input":"2024-01-29T18:16:35.737099Z","iopub.status.idle":"2024-01-29T18:16:36.186610Z","shell.execute_reply.started":"2024-01-29T18:16:35.737063Z","shell.execute_reply":"2024-01-29T18:16:36.185385Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#To create a Streamlit app for predicting the cost for a tourist, you can follow these steps. Note that you'll need to have Streamlit installed in your Python environment. You can install it using `pip install streamlit`.\n\n#1. Create a new Python file, e.g., `tourist_cost_app.py`.\n#2. Copy and paste the following code into your file:\n\n#```python\n# Importing the required libraries\nimport streamlit as st\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom xgboost import XGBRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\n# Load the dataset\ndata = pd.read_csv('/kaggle/input/clean-kenyan-dataset/Clean_Kenya_Tourism_datasets (2).csv')\n\n# Cleaning the data\n# ... (Copy the data cleaning code from your original code)\n\n# Convert categorical features to numeric\nfor colname in data.select_dtypes(\"object\"):\n    data[colname], _ = data[colname].factorize()\n\n# Feature engineering\ndata[\"total_people\"] = data[\"total_female\"] + data[\"total_male\"]\ndata[\"total_nights\"] = data[\"night_mainland\"]\ndata.drop('ID', axis='columns', inplace=True)\n\n# Split the data\nfeatures_cols = data.drop(columns=[\"total_cost\"])\ncols = features_cols.columns\ntarget = data[\"total_cost\"]\nX_train, X_test, y_train, y_test = train_test_split(data[cols], target, test_size=0.20, random_state=2020)\n\n# Model training\nXGB_par = XGBRegressor(n_estimators=100, colsample_bynode=0.8, learning_rate=0.02, max_depth=7)\nXGB_par.fit(X_train, y_train)\n\n# Streamlit app\nst.title(\"Tourist Cost Prediction App\")\n\n# Sidebar with input parameters\nst.sidebar.header(\"Input Parameters\")\ncountry = st.sidebar.selectbox(\"Country\", data[\"country\"].unique())\nage_group = st.sidebar.selectbox(\"Age Group\", data[\"age_group\"].unique())\ntravel_with = st.sidebar.selectbox(\"Travel With\", data[\"travel_with\"].unique())\ntotal_female = st.sidebar.slider(\"Total Female\", min_value=0, max_value=10, step=1, value=1)\ntotal_male = st.sidebar.slider(\"Total Male\", min_value=0, max_value=10, step=1, value=1)\npurpose = st.sidebar.selectbox(\"Purpose\", data[\"purpose\"].unique())\nmain_activity = st.sidebar.selectbox(\"Main Activity\", data[\"main_activity\"].unique())\ninfo_source = st.sidebar.selectbox(\"Info Source\", data[\"info_source\"].unique())\ntour_arrangement = st.sidebar.selectbox(\"Tour Arrangement\", data[\"tour_arrangement\"].unique())\npackage_transport_int = st.sidebar.selectbox(\"Package Transport\", data[\"package_transport_int\"].unique())\nnight_mainland = st.sidebar.slider(\"Night Mainland\", min_value=0, max_value=30, step=1, value=10)\npayment_mode = st.sidebar.selectbox(\"Payment Mode\", data[\"payment_mode\"].unique())\nfirst_trip_Kenya = st.sidebar.selectbox(\"First Trip to Kenya\", data[\"first_trip_Kenya\"].unique())\nmost_impressing = st.sidebar.selectbox(\"Most Impressing\", data[\"most_impressing\"].unique())\n\n# User input dictionary\nuser_input = {\n    \"country\": country,\n    \"age_group\": age_group,\n    \"travel_with\": travel_with,\n    \"total_female\": total_female,\n    \"total_male\": total_male,\n    \"purpose\": purpose,\n    \"main_activity\": main_activity,\n    \"info_source\": info_source,\n    \"tour_arrangement\": tour_arrangement,\n    \"package_transport_int\": package_transport_int,\n    \"night_mainland\": night_mainland,\n    \"payment_mode\": payment_mode,\n    \"first_trip_Kenya\": first_trip_Kenya,\n    \"most_impressing\": most_impressing,\n}\n\n# Create a DataFrame from the user input\nuser_input_df = pd.DataFrame([user_input])\n\n# Convert categorical features to numeric\nfor colname in user_input_df.select_dtypes(\"object\"):\n    user_input_df[colname], _ = user_input_df[colname].factorize()\n\n# Feature engineering\nuser_input_df[\"total_people\"] = user_input_df[\"total_female\"] + user_input_df[\"total_male\"]\nuser_input_df[\"total_nights\"] = user_input_df[\"night_mainland\"]\nuser_input_df.drop(columns=[\"total_female\", \"total_male\", \"night_mainland\"], inplace=True)\n\n# Predict the cost\nprediction = XGB_par.predict(user_input_df)[0]\n\n# Display the prediction\nst.header(\"Predicted Total Cost:\")\nst.write(f\"${prediction:,.2f}\")\n\n# Visualize predictions\nst.sidebar.header(\"Model Evaluation\")\nshow_plot = st.sidebar.checkbox(\"Show Predictions vs Residuals\")","metadata":{"execution":{"iopub.status.busy":"2024-01-29T19:03:00.677769Z","iopub.execute_input":"2024-01-29T19:03:00.678212Z","iopub.status.idle":"2024-01-29T19:03:00.751632Z","shell.execute_reply.started":"2024-01-29T19:03:00.678181Z","shell.execute_reply":"2024-01-29T19:03:00.750109Z"},"trusted":true},"execution_count":51,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[0;32mIn[51], line 8\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#To create a Streamlit app for predicting the cost for a tourist, you can follow these steps. Note that you'll need to have Streamlit installed in your Python environment. You can install it using `pip install streamlit`.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#1. Create a new Python file, e.g., `tourist_cost_app.py`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#```python\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Importing the required libraries\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mstreamlit\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mst\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'streamlit'"],"ename":"ModuleNotFoundError","evalue":"No module named 'streamlit'","output_type":"error"}]},{"cell_type":"markdown","source":"","metadata":{}}]}